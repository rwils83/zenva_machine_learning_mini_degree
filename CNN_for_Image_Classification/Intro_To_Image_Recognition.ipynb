{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Image Recognition with MNIST Notes: Introduction\n",
    "\n",
    "## Learning Goals\n",
    "* How does image recognition work?\n",
    "* What is MNIST?\n",
    "* How do I build a machine learning model to recognize and classify images with Tensorflow?\n",
    "* How do I build a machine learning model to recognize and classify images with Keras?\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* Some Python and numpy knowledge\n",
    "* A python development environment (course uses Anaconda and Jupyter notebooks)\n",
    "* An understanding of how machine learning works\n",
    "* Some experience with Tensorflow\n",
    "* Ideally Part 1 of this course (Intro to Machine Learning)\n",
    "\n",
    "## What topics will the course cover?\n",
    "\n",
    "* Intro to image recognition\n",
    "* Intro to MNIST\n",
    "* Build, train, and test an MNIST image recognition model\n",
    "* Build, train, and test an MNIST image recognition model with Keras\n",
    "\n",
    "## Why Image Recognition?\n",
    "\n",
    "* Image recognition is a fun and relatable topic\n",
    "* There are many practical applications for recognizing and classifying images\n",
    "* Once we understand how to build the model, it is easy to expand into other areas\n",
    "* MNSIT is an easy to use dataset\n",
    "\n",
    "# Part 2: Intro to Image Recognition\n",
    "\n",
    "## What is image recognition?\n",
    "\n",
    "* Image recognition is seeing an object or an image of an object and knowing what it is\n",
    "* Essentially class everything that we see into certain categories based on attributes\n",
    "* Even if we see something we have never seen before, we can usually place it in some category\n",
    "* For example, if we see a brand new model of car for the first time, we can tell that it is a car by the weheels, hood, windshield, seats, etc.\n",
    "\n",
    "## How does this work for us?\n",
    "\n",
    "* A lot of the time, image recognition for us happens subconsciously \n",
    "* We don't necessarily acknowledge everything that is around us\n",
    "* However, when we need to notice something, we can usually pick it out and define and describe it\n",
    "* Knowing what something is is based entirely on previous experiences\n",
    "* Some things we memorize, others we deduce based on shared characteristics that we see in things we do know\n",
    "* Subconsciously we separate the items we see based on borders defined primarily by differences in color\n",
    "* Example: It is easy to see a green leaf on a brown tree but hard to see a black cat against a black wall\n",
    "* We also don't necessarily need to look at every part of an image to know what some part of it is\n",
    "* Example: if we see only an eye and an ear of someone's face, we know we are looking at a face\n",
    "\n",
    "# Part three: How does this work for machines?\n",
    "\n",
    "* Machines do not have infinite knowledge of what everything they see is\n",
    "* They only have knowledge of the categories we have taught them\n",
    "* For example, if you create facial recognition, it only classifies images into faces or not faces\n",
    "* Even the most sophisticated image recognition models cannot recognize everything and have been trained only to look for certain objects\n",
    "* To a machine, an image is simply an array of bytes\n",
    "* Each pixel on an image contains information about red, green, and blue color values\n",
    "* If an image is just black or white, the value for each pixel is simply a darkness value, typcially with 255 as white and 0 as black\n",
    "* Machines don't care about seeing an image as a whole\n",
    "* To process an image, they simply look at the values for each of the bytes and look for patterns\n",
    "* In this way, image recognition models look for groups of similar byte values across images to place an image in a specific category\n",
    "* For example, high green and brown calues in adjacent bytes may suggest an image contains a tree. If many images all have similar groupings of green and brown values, the model may thing they all contain trees \n",
    "\n",
    "# Part four: Tools to help with image Recognition Part 1\n",
    "\n",
    "## The problem with processing images\n",
    "\n",
    "* Processing an entire image at a time is a lot\n",
    "* Most images fed into simple models are small (MNIST images are 28x28 pixels)\n",
    "* Even this leaves 784 pixels to examine and it's difficult to recognize consistent patterns when comparing all 784 pixel values of one image to another\n",
    "* Even if we are looking at two images of the same thing, slight position or size cahnges or slightly different shapes could lead to a mislabelling \n",
    "\n",
    "## How machines solve this\n",
    "\n",
    "* Machines solve this problem by first breaking down images into smaller parts and processing them instead\n",
    "* It starts by applying a sort of a filter to different parts of the image a few pixels at a time to produce seceral smaller, distorted images\n",
    "* Next, it makes the pieces more abstract by averaging together smaller squares of pixel values\n",
    "* This ultimately turns this image into something that may not be recognizable by humans but the machines can make sense of it\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "* The process of breaking down images and applying the filters is done in a concolutional layer in neural network\n",
    "* Averaging the values to further distort the images is done through a max pooling layer\n",
    "* Convolutional Neural Networks get their name from the fact that they have one or more convolutional layers\n",
    "* These are very popular in image recognition models, although RNNs have also performed well\n",
    "\n",
    "# Part five: Tools to help with image Recognition Part 2\n",
    "\n",
    "## Convolutions\n",
    "\n",
    "* Convulution: an operation on two functions to produce a third function that explains how the shape of one is modified by the other\n",
    "* Image convultion: applying a kernel or convolution mask to block of pixels to apply an effect\n",
    "* Ofen used to blur or sharpen images, or detect edges\n",
    "* A Kernal is a matrix used as a mask to image pixel values\n",
    "* Kernels are often pre-determined through Tensorflow objects\n",
    "\n",
    "## Max Pooling\n",
    "\n",
    "* Max Pooling: replacing a block of pixels by one pixel with the highest value out of the block\n",
    "* Makes an image more abstract\n",
    "* Used to downsize an image and also prevent overfitting (drawing conclusions when there are none)\n",
    "* Generally we specify the size of the matrix and the step size (number of pixels to skip over when applying the next max pool)\n",
    "\n",
    "## Putting it together\n",
    "\n",
    "* Almost all convultional neural networks will have a convolutional layer followed by a max pooling layer\n",
    "* Larger networks will repeat this one or more times along with other layers to perform additional processing\n",
    "* The result of the two layers is a set of smaller, more abstract images comprised of parts of the original image\n",
    "* The purpose is to cut out unnecessary image noise and to focus on the stand-out features so that the model can focus on what is important\n",
    "\n",
    "# Part six: MNIST\n",
    "\n",
    "## What is MNIST?\n",
    "\n",
    "* MNIST = Modern National Institute of Standards of Technology\n",
    "* We will use the dataset that MNIST is famous for\n",
    "* The dataset contains 70,000 images of handwritten digits\n",
    "* The even more modern EMNIST dataset was released in 2017 that contains 280,000 images\n",
    "\n",
    "## How are images Formatted?\n",
    "\n",
    "* 60,000 trianing images and 10,000 testing images\n",
    "* Each image is 28x28 pixels (784 total)\n",
    "* Each image is black and white\n",
    "* Each image is labelled based on which image it represents\n",
    "* Each label is in one-hot encoding form\n",
    "* Instead of a string label, we have an array of 0s and 1s with the 1 in the position that represents the digit and 0s in the rest\n",
    "\n",
    "## Why bother with MNIST?\n",
    "\n",
    "* Very highly esteemed data set\n",
    "* Starting point for many image recognition model\n",
    "* Great way to learn how to build an image recognition/classification model with a trusted and pre-formatted data set\n",
    "* Ongoing competition to see who can get the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}